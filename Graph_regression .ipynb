{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clHASL7wE5Em",
        "outputId": "59f4173f-1930-451e-f0fb-e1d739595bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.1.1-cp310-cp310-manylinux1_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.9)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Collecting sphinx>=4.2 (from numpydoc>=1.1.0->dglgo)\n",
            "  Downloading sphinx-7.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.16)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.6.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Collecting docutils<0.21,>=0.18.1 (from sphinx>=4.2->numpydoc>=1.1.0->dglgo)\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=694233521bb90c0a9da5a9edb99553b380bfe30f491b9963227c6d56de4c1c2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, autopep8, numpydoc, ogb, dglgo\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "Successfully installed autopep8-2.0.2 dglgo-0.0.2 docutils-0.20.1 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 sphinx-7.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl -f https://data.dgl.ai/wheels/repo.html\n",
        "\n",
        "!pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvoI20dxFCgX",
        "outputId": "896a45da-88e8-4f73-c24e-77bea895ee3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "tIqpZqNB9D9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"     #specifies that DGL should use PyTorch as the backend for operations on graphs\n",
        "import dgl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn                #contains a collection of built-in message-passing functions\n",
        "import torch.nn.functional as F          #provides a set of functions that can be used to define the behavior of neural network layers (F.relu())\n",
        "import shutil                            #provides a set of high-level operations on files and collections of files, such as copying, moving, and deleting files and directories.\n",
        "from torch.utils.data import DataLoader\n",
        "import cloudpickle                       #provides the ability to serialize and deserialize complex Python objects.\n",
        "from dgl.nn import GraphConv\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "7x74p1T2GAHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_dir = \"/content/drive/MyDrive/Graph_regression/\"\n",
        "\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True) #files for saving and resuming training,\n",
        "                                            #evaluating model performance,\n",
        "                                            # and making predictions on new data.\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\" #store data that is only needed temporarily,\n",
        "                                             #such as intermediate results or temporary copies of files.\n",
        "\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True) #function can be used to delete a directory and\n",
        "                                                    #its contents when it is no longer needed.\n",
        "\n",
        "path_save = current_dir + \"esol.zip\"\n",
        "shutil.unpack_archive(path_save, folder_data_temp) #This function automatically detects the archive\n",
        "                                                   #format and extracts the contents to the specified directory."
      ],
      "metadata": {
        "id": "XS1hWiWQGQis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Graph_regression/esol.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRA4SO1PII-6",
        "outputId": "e48fdc68-36e5-477f-8769-ef76c9b8ae23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Graph_regression/esol.zip\n",
            "  inflating: scaffold_0_smiles_train.pickle  \n",
            "  inflating: scaffold_0_test.bin     \n",
            "  inflating: scaffold_0_val.bin      \n",
            "  inflating: scaffold_0_smiles_val.pickle  \n",
            "  inflating: scaffold_0_smiles_test.pickle  \n",
            "  inflating: scaffold_0_train.bin    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression Dataset"
      ],
      "metadata": {
        "id": "RasYRX-GM_0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DGLDatasetReg(torch.utils.data.Dataset):\n",
        "    def __init__(self, address, transform=None, train=False, scaler=None):\n",
        "            self.transform = transform\n",
        "            self.train = train\n",
        "            self.scaler = scaler\n",
        "            self.list_graphs, train_labels_masks_globals = dgl.load_graphs(address+\"bin\") # load graphs and extract the labels, masks, and globals for the graphs.\n",
        "            num_graphs = len(self.list_graphs) #number of graphs in the datase\n",
        "            self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "            self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "            self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "\n",
        "\n",
        "\n",
        "    #scaler_method is used to ensure that the labels are normalized during training and testing.\n",
        "    #If self.train is True, it fits the scaler to the labels and returns it otherwise, it just\n",
        "    #returns the scaler that was fitted during training\n",
        "    def scaler_method(self):\n",
        "        if self.train:\n",
        "            scaler = StandardScaler().fit(self.labels)\n",
        "            self.scaler = scaler\n",
        "        return self.scaler\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_graphs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return  self.list_graphs[idx], torch.tensor(self.scaler.transform(self.labels)[idx]).float(), self.masks[idx], self.globals[idx] #This tuple represents a single example from the dataset."
      ],
      "metadata": {
        "id": "E3x-6WkKMpdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train_Validation_Test Set"
      ],
      "metadata": {
        "id": "4_v2BuPMRGeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_data_temp = folder_data_temp + \"scaffold\"+\"_\"+str(0)\n",
        "train_set = DGLDatasetReg(address=path_data_temp+\"_train.\", train=True)\n",
        "scaler = train_set.scaler_method()\n",
        "val_set = DGLDatasetReg(address=path_data_temp+\"_val.\", scaler=scaler)\n",
        "test_set = DGLDatasetReg(address=path_data_temp+\"_test.\", scaler=scaler)\n",
        "print('Size of train set : {}, Size of validation set : {}, Size of test set : {}'.format(len(train_set), len(val_set), len(test_set)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqpWgfGjPH5R",
        "outputId": "d536ed6e-75d2-4458-feb3-c27200356cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train set : 902, Size of validation set : 112, Size of test set : 114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader"
      ],
      "metadata": {
        "id": "6KqF-bWhT_3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The collate_fn argument specifies the function that should be used to collate the data from each batch into a single batch\n",
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "    graphs = [e[0] for e in batch]\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "    labels = [e[1] for e in batch]\n",
        "    labels = torch.stack(labels, 0) #stacked along the first (horizontal) dimension.\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "    masks = [e[2] for e in batch]\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "    globals = [e[3] for e in batch]\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "\n",
        "def loader(batch_size=64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=False,  #the last batch will be included even if it is smaller than the specified batch size.\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)    #specifies the number of worker processes that should be used to load the data in parallel.\n",
        "\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "m4CrYSMQSMBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=64)"
      ],
      "metadata": {
        "id": "8Zq6hit3UEPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some variables"
      ],
      "metadata": {
        "id": "rNkPJqdOHRp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_tasks = 1     #Esol dataset has 1 task.\n",
        "global_size = 200 # Size of global feature of each graph\n",
        "num_epochs = 100  # Number of epochs to train the model\n",
        "patience = 10     # Number of steps to wait if the model performance on the validation set does not improve\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}\n"
      ],
      "metadata": {
        "id": "bNGESz5DUNEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining GNN"
      ],
      "metadata": {
        "id": "8FUHNZ89XNjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL(1) :two GraphConv layers\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127) #returns the value associated with the key in the dictionary. If the key is not found in the dictionary, the method returns the default value 127.\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree='True')  #The allow_zero_in_degree parameter is set to True to allow nodes with zero incoming edges.\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree='True')\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size] #represents the node features and is sliced to the size of self.node_feature_size\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size] #represents the edge features and is sliced to the size of self.edge_feature_size.\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\") #The node-level representation is then aggregated to a single graph-level representation"
      ],
      "metadata": {
        "id": "c0jy4WKNVPch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute score of the model ---> RMSE"
      ],
      "metadata": {
        "id": "5vaiOQIEFFfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval() #switch for some specific parts of the model that behave differently during training and evaluating time\n",
        "    loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "    final_loss = 0\n",
        "    with torch.no_grad(): #turn off gradients computation\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader): #iterates over each batch of the DataLoader and computes the model's predictions for the batch.\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu())) #The predictions are transformed back to the original scale\n",
        "            labels = torch.tensor(scaler.inverse_transform(labels.cpu())) #The labels are then transformed back to the original scale\n",
        "                                                                          #when evaluating the model on new data, it is important to transform\n",
        "                                                                          #the model's outputs back to their original scale to obtain meaningful\n",
        "                                                                          #predictions that can be compared to the true values.\n",
        "\n",
        "            loss = loss_sum(prediction, labels)\n",
        "            final_loss += loss.item()\n",
        "        final_loss /= val_size\n",
        "        final_loss = np.sqrt(final_loss)  # RMSE\n",
        "    return final_loss / num_tasks"
      ],
      "metadata": {
        "id": "wChAWxNuBX2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining loss function"
      ],
      "metadata": {
        "id": "qLA7GmV9FIqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "B6xkxzZaZ-_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training"
      ],
      "metadata": {
        "id": "1Gl5BhQ4FVqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True) #clear any previous gradients that might still be stored in the optimizer.\n",
        "        loss_train.backward()  #update the model's parameters based\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ],
      "metadata": {
        "id": "pFbH5iYEaNUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate():  #The function saves the best model checkpoint based on the validation score and returns the average validation\n",
        "                       #score over the best checkpoints.\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = np.Inf\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience: #checks whether the patience count has exceeded the specified patience patience. If not:\n",
        "            model.train() #it trains the model for one epoch using the train_epoch function\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks) #computes the validation score using the compute_score function.\n",
        "            if score_val < best_val:#If the current best validation score is better than the validation score, the function saves the model checkpoint\n",
        "                                     #to a file using cloudpickle, updates the best_val variable, and resets the patience_count to 1. Otherwise,\n",
        "                                     #it increments the patience_count by 1\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile: #open function is called to open the file specified by the path variable in binary write mode (\"wb\").\n",
        "                                                     #Binary write mode (\"wb\") is a file mode in Python that is used to open a file for writing binary data.\n",
        "                                                     #In binary mode, the data is written to the file as a sequence of bytes, rather than as text characters.\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile) #serialize the dict_checkpoint dictionary and write the resulting bytes to the open file.\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    # Once the loop finishes, the function saves the best model checkpoint to a directory named best_model_path and prints the final average validation score\n",
        "    # based on the best checkpoints.\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True) #remove the best_model_path directory and its contents if it already exists.\n",
        "                                                       #The ignore_errors=True argument is provided to ignore any errors that might occur if the directory does not exist.\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ],
      "metadata": {
        "id": "UoZhcbN0bz2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluates the final GNN model on a test set and prints the test score.\n",
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth') #loads the best model checkpoint from the best_model_path directory using cloudpickle.load,\n",
        "                                                            #which reads the serialized dictionary from the file and returns it as a Python object.\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)#The function then computes the test score using the compute_score function on the test DataLoader\n",
        "\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ],
      "metadata": {
        "id": "44fbcl6ndDDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bvqSJFQd5ap",
        "outputId": "7efb6664-f540-4b55-acb9-14be415ba143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 1.015 | Valid Score: 2.177\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.177 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 1.001 | Valid Score: 2.187\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 2.177 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.953 | Valid Score: 2.188\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 2.177 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.944 | Valid Score: 2.166\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 2.166 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 5/100 | Training Loss: 0.933 | Valid Score: 2.169\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 2.166 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 6/100 | Training Loss: 0.943 | Valid Score: 2.173\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 2.166 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 7/100 | Training Loss: 0.898 | Valid Score: 2.168\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 2.166 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.932 | Valid Score: 2.154\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 2.154 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.964 | Valid Score: 2.148\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 2.148 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.926 | Valid Score: 2.139\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 2.139 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 11/100 | Training Loss: 0.878 | Valid Score: 2.146\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 2.139 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 12/100 | Training Loss: 0.905 | Valid Score: 2.146\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 2.139 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 13/100 | Training Loss: 0.888 | Valid Score: 2.140\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 2.139 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 14/100 | Training Loss: 0.950 | Valid Score: 2.156\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 2.139 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 15/100 | Training Loss: 0.902 | Valid Score: 2.149\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 2.139 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.876 | Valid Score: 2.130\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 2.130 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.859 | Valid Score: 2.129\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.129 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.885 | Valid Score: 2.126\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.126 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.842 | Valid Score: 2.112\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.112 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 0.875 | Valid Score: 2.114\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.112 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 21/100 | Training Loss: 0.947 | Valid Score: 2.132\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.112 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 22/100 | Training Loss: 0.895 | Valid Score: 2.123\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.112 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 23/100 | Training Loss: 0.842 | Valid Score: 2.118\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 2.112 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.840 | Valid Score: 2.111\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 2.111 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 0.822 | Valid Score: 2.120\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 2.111 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 26/100 | Training Loss: 0.808 | Valid Score: 2.112\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 2.111 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.834 | Valid Score: 2.100\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 2.100 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.894 | Valid Score: 2.102\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 2.100 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 29/100 | Training Loss: 0.803 | Valid Score: 2.104\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 2.100 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 30/100 | Training Loss: 0.807 | Valid Score: 2.104\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 2.100 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 31/100 | Training Loss: 0.806 | Valid Score: 2.102\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 2.100 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.803 | Valid Score: 2.095\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 2.095 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 0.832 | Valid Score: 2.097\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 2.095 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 0.810 | Valid Score: 2.095\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 2.095 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.771 | Valid Score: 2.094\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 2.094 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 36/100 | Training Loss: 0.821 | Valid Score: 2.096\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 2.094 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 0.798 | Valid Score: 2.086\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 2.086 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 38/100 | Training Loss: 0.772 | Valid Score: 2.088\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 2.086 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.787 | Valid Score: 2.074\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 2.074 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.788 | Valid Score: 2.063\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 2.063 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 41/100 | Training Loss: 0.868 | Valid Score: 2.081\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 2.063 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 42/100 | Training Loss: 0.841 | Valid Score: 2.081\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 2.063 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 43/100 | Training Loss: 0.775 | Valid Score: 2.065\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 2.063 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 44/100 | Training Loss: 0.872 | Valid Score: 2.065\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 2.063 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 0.773 | Valid Score: 2.059\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 2.059 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 46/100 | Training Loss: 0.771 | Valid Score: 2.064\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 2.059 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 47/100 | Training Loss: 0.760 | Valid Score: 2.066\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 2.059 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 48/100 | Training Loss: 0.758 | Valid Score: 2.068\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 2.059 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 49/100 | Training Loss: 0.774 | Valid Score: 2.073\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 2.059 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 50/100 | Training Loss: 0.781 | Valid Score: 2.070\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 2.059 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 51/100 | Training Loss: 0.765 | Valid Score: 2.075\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 2.059 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 52/100 | Training Loss: 0.837 | Valid Score: 2.069\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 2.059 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 0.851 | Valid Score: 2.049\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 2.049 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 54/100 | Training Loss: 0.807 | Valid Score: 2.049\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 2.049 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 55/100 | Training Loss: 0.825 | Valid Score: 2.051\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 2.049 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 56/100 | Training Loss: 0.740 | Valid Score: 2.049\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 2.049 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 0.764 | Valid Score: 2.046\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 2.046 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 58/100 | Training Loss: 0.768 | Valid Score: 2.052\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 2.046 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 59/100 | Training Loss: 0.734 | Valid Score: 2.050\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 2.046 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 0.739 | Valid Score: 2.045\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 2.045 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 0.726 | Valid Score: 2.044\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 2.044 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 0.879 | Valid Score: 2.039\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 2.039 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 0.764 | Valid Score: 2.032\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 2.032 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 64/100 | Training Loss: 0.797 | Valid Score: 2.036\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 2.032 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.783 | Valid Score: 2.025\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 2.025 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 0.781 | Valid Score: 2.025\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 2.025 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 0.816 | Valid Score: 2.022\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 2.022 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.724 | Valid Score: 2.018\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 2.018 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 0.762 | Valid Score: 2.026\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 2.018 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 70/100 | Training Loss: 0.727 | Valid Score: 2.029\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 2.018 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 71/100 | Training Loss: 0.747 | Valid Score: 2.025\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 2.018 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 72/100 | Training Loss: 0.721 | Valid Score: 2.030\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 2.018 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 73/100 | Training Loss: 0.731 | Valid Score: 2.030\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 2.018 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 74/100 | Training Loss: 0.786 | Valid Score: 2.035\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 2.018 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 0.727 | Valid Score: 2.015\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 2.015 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 0.735 | Valid Score: 2.015\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 2.015 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 77/100 | Training Loss: 0.765 | Valid Score: 2.027\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 2.015 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 78/100 | Training Loss: 0.727 | Valid Score: 2.022\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 2.015 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 79/100 | Training Loss: 0.743 | Valid Score: 2.016\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 2.015 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 80/100 | Training Loss: 0.715 | Valid Score: 2.015\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 2.015 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 0.746 | Valid Score: 2.011\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 2.011 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 0.730 | Valid Score: 2.018\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 2.011 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 83/100 | Training Loss: 0.715 | Valid Score: 2.021\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 2.011 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 84/100 | Training Loss: 0.703 | Valid Score: 2.023\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 2.011 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 85/100 | Training Loss: 0.710 | Valid Score: 2.022\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 2.011 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 86/100 | Training Loss: 0.730 | Valid Score: 2.014\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 2.011 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 0.792 | Valid Score: 2.007\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 2.007 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 0.728 | Valid Score: 1.990\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.990 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 89/100 | Training Loss: 0.713 | Valid Score: 1.994\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.990 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 90/100 | Training Loss: 0.715 | Valid Score: 2.009\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.990 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 91/100 | Training Loss: 0.715 | Valid Score: 2.012\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.990 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 92/100 | Training Loss: 0.688 | Valid Score: 1.999\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.990 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 93/100 | Training Loss: 0.703 | Valid Score: 1.994\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.990 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 94/100 | Training Loss: 0.696 | Valid Score: 1.996\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.990 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 95/100 | Training Loss: 0.699 | Valid Score: 1.992\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.990 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 96/100 | Training Loss: 0.694 | Valid Score: 1.989\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.989 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 97/100 | Training Loss: 0.728 | Valid Score: 2.002\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.989 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 98/100 | Training Loss: 0.691 | Valid Score: 1.995\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.989 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 99/100 | Training Loss: 0.722 | Valid Score: 2.009\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.989 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 100/100 | Training Loss: 0.724 | Valid Score: 1.980\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.980 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.980 \n",
            "\n",
            "Test Score: 2.577 \n",
            "\n",
            "Execution time: 63.817 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Desired_GNN_1(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(Desired_GNN_1, self).__init__()\n",
        "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # update_all is a message passing API.\n",
        "            g.update_all(\n",
        "                message_func=fn.u_add_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.mean(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "BLldp8fLd8KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL(2)\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = Desired_GNN_1(self.node_feature_size, self.hidden_size )\n",
        "        self.conv2 = Desired_GNN_1(self.hidden_size, self.num_tasks )\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "sPHUdOXyIHw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yeyh2oGIVpa",
        "outputId": "300fe58b-928f-452e-bde3-6e857f57e4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.960 | Valid Score: 2.157\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.157 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 1.007 | Valid Score: 2.169\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 2.157 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.943 | Valid Score: 2.153\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 2.153 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.921 | Valid Score: 2.141\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 2.141 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.960 | Valid Score: 2.135\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 2.135 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 6/100 | Training Loss: 0.921 | Valid Score: 2.138\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 2.135 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 7/100 | Training Loss: 0.932 | Valid Score: 2.146\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 2.135 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 8/100 | Training Loss: 0.945 | Valid Score: 2.149\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 2.135 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.898 | Valid Score: 2.110\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 2.110 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 10/100 | Training Loss: 0.889 | Valid Score: 2.123\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 2.110 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 11/100 | Training Loss: 0.897 | Valid Score: 2.123\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 2.110 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.850 | Valid Score: 2.108\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 2.108 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 13/100 | Training Loss: 0.846 | Valid Score: 2.135\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 2.108 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 14/100 | Training Loss: 0.869 | Valid Score: 2.121\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 2.108 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 15/100 | Training Loss: 0.827 | Valid Score: 2.120\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 2.108 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 16/100 | Training Loss: 0.824 | Valid Score: 2.117\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 2.108 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.845 | Valid Score: 2.106\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.106 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 18/100 | Training Loss: 0.820 | Valid Score: 2.112\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.106 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 19/100 | Training Loss: 0.855 | Valid Score: 2.118\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.106 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 20/100 | Training Loss: 0.820 | Valid Score: 2.115\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.106 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.862 | Valid Score: 2.090\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.090 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.871 | Valid Score: 2.081\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.081 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 23/100 | Training Loss: 0.802 | Valid Score: 2.130\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 2.081 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 24/100 | Training Loss: 0.839 | Valid Score: 2.096\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 2.081 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.778 | Valid Score: 2.067\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 26/100 | Training Loss: 0.764 | Valid Score: 2.082\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 27/100 | Training Loss: 0.766 | Valid Score: 2.070\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 0.833 | Valid Score: 2.062\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 2.062 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 29/100 | Training Loss: 0.779 | Valid Score: 2.067\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 2.062 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 0.793 | Valid Score: 2.047\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 2.047 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.746 | Valid Score: 2.034\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 2.034 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 0.753 | Valid Score: 2.056\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 2.034 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 33/100 | Training Loss: 0.782 | Valid Score: 2.055\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 2.034 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 0.741 | Valid Score: 2.031\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 2.031 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.776 | Valid Score: 2.030\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 2.030 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.753 | Valid Score: 2.016\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 2.016 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 37/100 | Training Loss: 0.745 | Valid Score: 2.054\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 2.016 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.753 | Valid Score: 2.011\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 2.011 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 39/100 | Training Loss: 0.719 | Valid Score: 2.030\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 2.011 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.760 | Valid Score: 2.004\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 2.004 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.748 | Valid Score: 1.983\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.983 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 42/100 | Training Loss: 0.749 | Valid Score: 2.021\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.983 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.763 | Valid Score: 1.976\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.976 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 0.708 | Valid Score: 1.997\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.976 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 45/100 | Training Loss: 0.758 | Valid Score: 1.994\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.976 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 0.713 | Valid Score: 1.962\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.962 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 0.697 | Valid Score: 1.996\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.962 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 48/100 | Training Loss: 0.724 | Valid Score: 1.974\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.962 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 49/100 | Training Loss: 0.714 | Valid Score: 1.964\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.962 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 50/100 | Training Loss: 0.734 | Valid Score: 1.970\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.962 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 0.687 | Valid Score: 1.953\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.953 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 0.698 | Valid Score: 1.972\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.953 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 53/100 | Training Loss: 0.679 | Valid Score: 1.958\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.953 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 0.718 | Valid Score: 1.931\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.931 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 55/100 | Training Loss: 0.778 | Valid Score: 1.940\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.931 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.693 | Valid Score: 1.931\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.931 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 0.680 | Valid Score: 1.947\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.931 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 0.718 | Valid Score: 1.947\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.931 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 0.706 | Valid Score: 1.914\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.914 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 60/100 | Training Loss: 0.669 | Valid Score: 1.921\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.914 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 61/100 | Training Loss: 0.723 | Valid Score: 1.915\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.914 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 62/100 | Training Loss: 0.677 | Valid Score: 1.921\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.914 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 0.670 | Valid Score: 1.902\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.902 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.695 | Valid Score: 1.896\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.896 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 65/100 | Training Loss: 0.673 | Valid Score: 1.910\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.896 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 66/100 | Training Loss: 0.678 | Valid Score: 1.896\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.896 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 67/100 | Training Loss: 0.643 | Valid Score: 1.914\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.896 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.660 | Valid Score: 1.887\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.887 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 0.634 | Valid Score: 1.900\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.887 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 0.633 | Valid Score: 1.886\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.886 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 0.642 | Valid Score: 1.904\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.886 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 0.625 | Valid Score: 1.883\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.883 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 0.635 | Valid Score: 1.885\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.883 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 74/100 | Training Loss: 0.660 | Valid Score: 1.903\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.883 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 0.644 | Valid Score: 1.852\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.852 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 0.617 | Valid Score: 1.901\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.852 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 77/100 | Training Loss: 0.615 | Valid Score: 1.858\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.852 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 78/100 | Training Loss: 0.632 | Valid Score: 1.881\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.852 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 79/100 | Training Loss: 0.625 | Valid Score: 1.859\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.852 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 80/100 | Training Loss: 0.702 | Valid Score: 1.866\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.852 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 81/100 | Training Loss: 0.610 | Valid Score: 1.862\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.852 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 82/100 | Training Loss: 0.678 | Valid Score: 1.841\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.841 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 83/100 | Training Loss: 0.626 | Valid Score: 1.863\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.841 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 84/100 | Training Loss: 0.639 | Valid Score: 1.844\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.841 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 85/100 | Training Loss: 0.629 | Valid Score: 1.864\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.841 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 0.608 | Valid Score: 1.834\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.834 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 0.678 | Valid Score: 1.829\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.829 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 88/100 | Training Loss: 0.595 | Valid Score: 1.841\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.829 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 0.710 | Valid Score: 1.827\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.827 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 0.593 | Valid Score: 1.833\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.827 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 91/100 | Training Loss: 0.636 | Valid Score: 1.833\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.827 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 0.680 | Valid Score: 1.815\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.815 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 0.618 | Valid Score: 1.813\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.813 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 94/100 | Training Loss: 0.641 | Valid Score: 1.826\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.813 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 95/100 | Training Loss: 0.591 | Valid Score: 1.818\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 96/100 | Training Loss: 0.601 | Valid Score: 1.812\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 0.584 | Valid Score: 1.792\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.792 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 98/100 | Training Loss: 0.602 | Valid Score: 1.802\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.792 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 99/100 | Training Loss: 0.596 | Valid Score: 1.814\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.792 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 100/100 | Training Loss: 0.636 | Valid Score: 1.782\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.782 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.782 \n",
            "\n",
            "Test Score: 2.270 \n",
            "\n",
            "Execution time: 60.963 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Desired_GNN_2(nn.Module):\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(Desired_GNN_2, self).__init__()\n",
        "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # update_all is a message passing API.\n",
        "            g.update_all(\n",
        "                message_func=fn.u_mul_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.sum(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "Hc5goKq2IYtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL(3)\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = Desired_GNN_2(self.node_feature_size, self.hidden_size )\n",
        "        self.conv2 = Desired_GNN_2(self.hidden_size, self.num_tasks )\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "7pfoO303Ih4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfcEiRy5Ikwd",
        "outputId": "d336b27a-4527-40d5-e3a9-489c50578ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 1.012 | Valid Score: 2.111\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.111 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 1.066 | Valid Score: 2.095\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 2.095 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.949 | Valid Score: 2.078\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 2.078 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.976 | Valid Score: 2.067\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 5/100 | Training Loss: 1.047 | Valid Score: 2.078\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 6/100 | Training Loss: 0.981 | Valid Score: 2.074\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 7/100 | Training Loss: 0.897 | Valid Score: 2.072\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 8/100 | Training Loss: 0.901 | Valid Score: 2.070\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 9/100 | Training Loss: 0.990 | Valid Score: 2.073\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 10/100 | Training Loss: 0.918 | Valid Score: 2.069\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 11/100 | Training Loss: 0.895 | Valid Score: 2.069\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 12/100 | Training Loss: 0.863 | Valid Score: 2.077\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 13/100 | Training Loss: 0.878 | Valid Score: 2.079\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 14/100 | Training Loss: 0.862 | Valid Score: 2.079\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 2.067 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 2.067 \n",
            "\n",
            "Test Score: 3.126 \n",
            "\n",
            "Execution time: 8.664 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL(4)\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = Desired_GNN_2(self.node_feature_size, self.hidden_size )\n",
        "        self.conv2 = Desired_GNN_2(self.hidden_size, self.hidden_size )\n",
        "        self.conv3 = Desired_GNN_2(self.hidden_size, self.hidden_size )\n",
        "        self.conv4 = Desired_GNN_2(self.hidden_size, self.num_tasks )\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "-pgjafcJInnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV5XzgXZItnu",
        "outputId": "8dc37123-4458-46cd-9883-d7ac96dda68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 1.153 | Valid Score: 2.125\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.125 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 0.962 | Valid Score: 2.125\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 2.125 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.998 | Valid Score: 2.126\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 2.125 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 0.992 | Valid Score: 2.128\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 2.125 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 5/100 | Training Loss: 0.961 | Valid Score: 2.130\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 2.125 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 6/100 | Training Loss: 0.949 | Valid Score: 2.130\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 2.125 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 7/100 | Training Loss: 0.931 | Valid Score: 2.130\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 2.125 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 8/100 | Training Loss: 0.969 | Valid Score: 2.130\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 2.125 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 9/100 | Training Loss: 1.018 | Valid Score: 2.126\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 2.125 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.979 | Valid Score: 2.124\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 2.124 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.975 | Valid Score: 2.114\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 2.114 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 12/100 | Training Loss: 0.912 | Valid Score: 2.129\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 2.114 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 13/100 | Training Loss: 0.969 | Valid Score: 2.134\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 2.114 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 14/100 | Training Loss: 0.862 | Valid Score: 2.121\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 2.114 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.886 | Valid Score: 2.111\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 2.111 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 16/100 | Training Loss: 0.805 | Valid Score: 2.115\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 2.111 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 17/100 | Training Loss: 0.815 | Valid Score: 2.120\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 2.111 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.744 | Valid Score: 2.082\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 19/100 | Training Loss: 0.766 | Valid Score: 2.086\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 2.082 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.774 | Valid Score: 2.056\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 2.056 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.767 | Valid Score: 2.014\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 2.014 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 22/100 | Training Loss: 0.692 | Valid Score: 2.034\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 2.014 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.698 | Valid Score: 1.996\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.996 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.643 | Valid Score: 1.966\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.966 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 0.656 | Valid Score: 1.980\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.966 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.703 | Valid Score: 1.954\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.954 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.635 | Valid Score: 1.937\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.937 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.656 | Valid Score: 1.960\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.937 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.581 | Valid Score: 1.923\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.923 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 0.584 | Valid Score: 1.935\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.923 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.633 | Valid Score: 1.896\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.896 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 0.600 | Valid Score: 1.918\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.896 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.588 | Valid Score: 1.880\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.880 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.554 | Valid Score: 1.883\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.880 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.570 | Valid Score: 1.859\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.859 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.554 | Valid Score: 1.849\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.849 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 0.571 | Valid Score: 1.834\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.834 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.584 | Valid Score: 1.816\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.816 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.529 | Valid Score: 1.809\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.809 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.545 | Valid Score: 1.796\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.796 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 41/100 | Training Loss: 0.539 | Valid Score: 1.804\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.796 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 42/100 | Training Loss: 0.563 | Valid Score: 1.801\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.796 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 43/100 | Training Loss: 0.542 | Valid Score: 1.798\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.796 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 44/100 | Training Loss: 0.514 | Valid Score: 1.806\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.796 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 0.557 | Valid Score: 1.750\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.750 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 46/100 | Training Loss: 0.527 | Valid Score: 1.763\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.750 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 0.521 | Valid Score: 1.748\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.748 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 0.512 | Valid Score: 1.739\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.739 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.555 | Valid Score: 1.738\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.738 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 0.508 | Valid Score: 1.737\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.737 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 51/100 | Training Loss: 0.543 | Valid Score: 1.757\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.737 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 0.524 | Valid Score: 1.707\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.707 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 53/100 | Training Loss: 0.622 | Valid Score: 1.795\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.707 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 54/100 | Training Loss: 0.539 | Valid Score: 1.757\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.707 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 55/100 | Training Loss: 0.499 | Valid Score: 1.734\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.707 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 56/100 | Training Loss: 0.502 | Valid Score: 1.717\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.707 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 57/100 | Training Loss: 0.511 | Valid Score: 1.715\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.707 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 58/100 | Training Loss: 0.518 | Valid Score: 1.720\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.707 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 0.487 | Valid Score: 1.689\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.689 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 60/100 | Training Loss: 0.481 | Valid Score: 1.697\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.689 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 61/100 | Training Loss: 0.465 | Valid Score: 1.692\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.689 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 0.492 | Valid Score: 1.677\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.677 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 0.472 | Valid Score: 1.643\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.643 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 64/100 | Training Loss: 0.475 | Valid Score: 1.660\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.643 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.470 | Valid Score: 1.642\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.642 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 0.463 | Valid Score: 1.676\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.642 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 0.468 | Valid Score: 1.619\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.619 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 68/100 | Training Loss: 0.468 | Valid Score: 1.663\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.619 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 69/100 | Training Loss: 0.455 | Valid Score: 1.654\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.619 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 70/100 | Training Loss: 0.451 | Valid Score: 1.632\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.619 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 71/100 | Training Loss: 0.459 | Valid Score: 1.651\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.619 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 0.479 | Valid Score: 1.615\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.615 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 0.463 | Valid Score: 1.653\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.615 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 74/100 | Training Loss: 0.442 | Valid Score: 1.619\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.615 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 75/100 | Training Loss: 0.441 | Valid Score: 1.635\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.615 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 76/100 | Training Loss: 0.444 | Valid Score: 1.616\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.615 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 0.431 | Valid Score: 1.611\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.611 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 78/100 | Training Loss: 0.460 | Valid Score: 1.624\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.611 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 0.480 | Valid Score: 1.590\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.590 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 0.469 | Valid Score: 1.606\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.590 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 0.457 | Valid Score: 1.582\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.582 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 0.471 | Valid Score: 1.593\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.582 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 83/100 | Training Loss: 0.445 | Valid Score: 1.613\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.582 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 84/100 | Training Loss: 0.469 | Valid Score: 1.603\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.582 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 85/100 | Training Loss: 0.436 | Valid Score: 1.641\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.582 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 0.458 | Valid Score: 1.564\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.564 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 87/100 | Training Loss: 0.428 | Valid Score: 1.567\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.564 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 88/100 | Training Loss: 0.442 | Valid Score: 1.587\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.564 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 0.442 | Valid Score: 1.563\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 0.438 | Valid Score: 1.602\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 91/100 | Training Loss: 0.430 | Valid Score: 1.582\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 92/100 | Training Loss: 0.450 | Valid Score: 1.587\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 93/100 | Training Loss: 0.504 | Valid Score: 1.599\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 94/100 | Training Loss: 0.434 | Valid Score: 1.600\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 95/100 | Training Loss: 0.438 | Valid Score: 1.604\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 96/100 | Training Loss: 0.404 | Valid Score: 1.585\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 97/100 | Training Loss: 0.407 | Valid Score: 1.594\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 98/100 | Training Loss: 0.420 | Valid Score: 1.587\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 99/100 | Training Loss: 0.423 | Valid Score: 1.568\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.563 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.563 \n",
            "\n",
            "Test Score: 2.123 \n",
            "\n",
            "Execution time: 63.318 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL(5)\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = Desired_GNN_2(self.node_feature_size, self.hidden_size )\n",
        "        self.bn1 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.conv2 = Desired_GNN_2(self.hidden_size, self.hidden_size )\n",
        "        self.bn2 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.conv3 = Desired_GNN_2(self.hidden_size, self.hidden_size )\n",
        "        self.bn3 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.conv4 = Desired_GNN_2(self.hidden_size, self.num_tasks )\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = self.bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = self.bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = self.bn3(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "ZUtysDAsI-uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdRkihC8JErU",
        "outputId": "7346ac82-62ee-47e1-d89f-d56c9f00874f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 2.534 | Valid Score: 2.212\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 1.503 | Valid Score: 2.820\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 1.306 | Valid Score: 5.262\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 1.198 | Valid Score: 5.824\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 5/100 | Training Loss: 1.346 | Valid Score: 4.119\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 6/100 | Training Loss: 1.186 | Valid Score: 2.875\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 7/100 | Training Loss: 1.260 | Valid Score: 4.749\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 8/100 | Training Loss: 1.169 | Valid Score: 9.598\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 9/100 | Training Loss: 1.184 | Valid Score: 11.419\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 10/100 | Training Loss: 1.095 | Valid Score: 5.085\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 11/100 | Training Loss: 1.031 | Valid Score: 4.432\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 2.212 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 2.212 \n",
            "\n",
            "Test Score: 3.260 \n",
            "\n",
            "Execution time: 7.240 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL(6)\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = Desired_GNN_2(self.node_feature_size, self.hidden_size )\n",
        "        self.bn1 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.d1 = nn.Dropout(0.5)\n",
        "        self.conv2 = Desired_GNN_2(self.hidden_size, self.hidden_size )\n",
        "        self.bn2 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.conv3 = Desired_GNN_2(self.hidden_size, self.hidden_size )\n",
        "        self.bn3 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.d2 = nn.Dropout(0.5)\n",
        "        self.conv4 = Desired_GNN_2(self.hidden_size, self.num_tasks )\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = self.bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.d1(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = self.bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = self.bn3(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.d2(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "4-L0YmMDJIgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfqwAfTlJRAg",
        "outputId": "4dc804a2-2dbc-4c54-9e59-fc131c279f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 8.064 | Valid Score: 2.180\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 6.841 | Valid Score: 2.195\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 8.168 | Valid Score: 2.203\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 4.936 | Valid Score: 2.376\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 5/100 | Training Loss: 5.693 | Valid Score: 2.379\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 6/100 | Training Loss: 6.297 | Valid Score: 2.208\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 7/100 | Training Loss: 4.077 | Valid Score: 2.200\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 8/100 | Training Loss: 5.307 | Valid Score: 2.324\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 9/100 | Training Loss: 6.145 | Valid Score: 2.194\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 10/100 | Training Loss: 4.617 | Valid Score: 2.329\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 11/100 | Training Loss: 7.947 | Valid Score: 2.373\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 2.180 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 2.180 \n",
            "\n",
            "Test Score: 3.225 \n",
            "\n",
            "Execution time: 8.013 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlgvLqnFJUf7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}